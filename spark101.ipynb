{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28bcdcc3",
   "metadata": {},
   "source": [
    "### 1. Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "- The name of the column should be `language`\n",
    "- View the schema of the dataframe\n",
    "- Output the shape of the dataframe\n",
    "- Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27846c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "\n",
    "# create spark environment\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f54ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scala</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language\n",
       "0   python\n",
       "1      sql\n",
       "2     html\n",
       "3     ruby\n",
       "4        c\n",
       "5    scala"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create pandas dataframe\n",
    "p_df = pd.DataFrame({'language':['python', 'sql', 'html', 'ruby', 'c', 'scala']})\n",
    "p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09d266ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark dataframe\n",
    "df = spark.createDataFrame(p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52ef818c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8490d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape:  6  x  1\n"
     ]
    }
   ],
   "source": [
    "# output shape\n",
    "print(\"DataFrame shape: \", df.count(), \" x \", len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e02421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "|  python|\n",
      "|     sql|\n",
      "|    html|\n",
      "|    ruby|\n",
      "|       c|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view first 5 records\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba4640d",
   "metadata": {},
   "source": [
    "### 2. Load the `mpg` dataset as a spark dataframe.\n",
    "\n",
    "#### a. Create 1 column of output that contains a message like the one below for each record:\n",
    "\n",
    "    The 1999 audi a4 has a 4 cylinder engine.\n",
    "\n",
    "> Hint: You will need to concatenate values that already exist in the data with string literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c9ae6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from pydataset import data\n",
    "\n",
    "# create dataframe\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))\n",
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0524939f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+\n",
      "|message                                  |\n",
      "+-----------------------------------------+\n",
      "|The 1999 audi a4 has a 4 cylinder engine.|\n",
      "|The 1999 audi a4 has a 4 cylinder engine.|\n",
      "|The 2008 audi a4 has a 4 cylinder engine.|\n",
      "|The 2008 audi a4 has a 4 cylinder engine.|\n",
      "|The 1999 audi a4 has a 6 cylinder engine.|\n",
      "+-----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import concat\n",
    "\n",
    "# create string column\n",
    "mpg.select(concat(lit(\"The \"),\n",
    "                  mpg.year,\n",
    "                  lit(\" \"),\n",
    "                  mpg.manufacturer,\n",
    "                  lit(\" \"),\n",
    "                  mpg.model,\n",
    "                  lit(\" has a \"),\n",
    "                  mpg.cyl,\n",
    "                  lit(\" cylinder engine.\"))\n",
    "          .alias(\"message\")\n",
    "          ).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808345d8",
   "metadata": {},
   "source": [
    "#### b. Transform the trans column so that it only contains either manual or auto.\n",
    "\n",
    "> Hint: Consider spark string methods and `when().otherwise()` chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab7553ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|     model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+----------+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|        a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|        a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|        a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|        a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|        a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "|        audi|        a4|  2.8|1999|  6|manual(m5)|  f| 18| 26|  p|compact|\n",
      "|        audi|        a4|  3.1|2008|  6|  auto(av)|  f| 18| 27|  p|compact|\n",
      "|        audi|a4 quattro|  1.8|1999|  4|manual(m5)|  4| 18| 26|  p|compact|\n",
      "|        audi|a4 quattro|  1.8|1999|  4|  auto(l5)|  4| 16| 25|  p|compact|\n",
      "|        audi|a4 quattro|  2.0|2008|  4|manual(m6)|  4| 20| 28|  p|compact|\n",
      "+------------+----------+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# preview dataframe\n",
    "mpg.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bcc0d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|     trans|trans_type|\n",
      "+----------+----------+\n",
      "|  auto(l5)|      auto|\n",
      "|manual(m5)|    manual|\n",
      "|manual(m6)|    manual|\n",
      "|  auto(av)|      auto|\n",
      "|  auto(l5)|      auto|\n",
      "|manual(m5)|    manual|\n",
      "|  auto(av)|      auto|\n",
      "|manual(m5)|    manual|\n",
      "|  auto(l5)|      auto|\n",
      "|manual(m6)|    manual|\n",
      "+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from pyspark.sql.functions import when, regexp_extract, regexp_replace, col, round\n",
    "\n",
    "mpg.select(mpg.trans, \n",
    "           when(mpg.trans.like(\"a%\"), \"auto\")\n",
    "           .otherwise(\"manual\")\n",
    "           .alias(\"trans_type\")\n",
    "          ).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476b9e6b",
   "metadata": {},
   "source": [
    "### 3. Load the `tips` dataset as a spark dataframe.\n",
    "\n",
    "#### a. What percentage of observations are smokers?\n",
    "> Hint: `.groupBy()` and `.withColumn()` are useful functions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a92274a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get tips data\n",
    "tips = spark.createDataFrame(data(\"tips\"))\n",
    "tips.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "797138ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----------+\n",
      "|smoker|count|percentage|\n",
      "+------+-----+----------+\n",
      "|    No|  151|      0.62|\n",
      "|   Yes|   93|      0.38|\n",
      "+------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show proportion of smokers vs non-smokers\n",
    "tips.groupBy(\"smoker\").count().withColumn(\"percentage\", \n",
    "                                         round(col(\"count\")/tips.count(), 2)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a836295",
   "metadata": {},
   "source": [
    "#### b. Create a column that contains the tip percentage\n",
    "> Hint: `.withColumn()` is useful here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4222dfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+--------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|tip_percentage|\n",
      "+----------+----+------+------+---+------+----+--------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|          0.06|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|          0.16|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|          0.17|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|          0.14|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|          0.15|\n",
      "+----------+----+------+------+---+------+----+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add tip percentage column\n",
    "tips.withColumn(\"tip_percentage\", round(tips.tip/tips.total_bill, 2)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab16ff7",
   "metadata": {},
   "source": [
    "#### c. Calculate the average tip percentage for each combination of sex and smoker.\n",
    "> Hint: Chain additional functions off the answer to part b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8aa37c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-------------------+\n",
      "|smoker|   sex|avg(tip_percentage)|\n",
      "+------+------+-------------------+\n",
      "|    No|Female| 0.1569209707691836|\n",
      "|    No|  Male| 0.1606687151291298|\n",
      "|   Yes|  Male|0.15277117520248512|\n",
      "|   Yes|Female|0.18215035269941032|\n",
      "+------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from pyspark.sql.functions import avg\n",
    "# get tip percentages\n",
    "tips.withColumn(\"tip_percentage\", tips.tip/tips.total_bill).groupBy(\"smoker\", \"sex\").agg(avg(\"tip_percentage\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b9da271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+-------------------+\n",
      "|smoker|             Female|               Male|\n",
      "+------+-------------------+-------------------+\n",
      "|    No| 0.1569209707691836| 0.1606687151291298|\n",
      "|   Yes|0.18215035269941032|0.15277117520248512|\n",
      "+------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# do the same using a pivot table\n",
    "tips.withColumn(\"tip_percentage\", tips.tip/tips.total_bill).groupBy(\"smoker\").pivot(\"sex\").agg(avg(\"tip_percentage\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8169018d",
   "metadata": {},
   "source": [
    "### 4. Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "- Convert the temperatures to fahrenheit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaaf11a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|               date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05 00:00:00|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get seattle weather data\n",
    "from vega_datasets import data\n",
    "\n",
    "weather = data.seattle_weather()\n",
    "weather = spark.createDataFrame(weather)\n",
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f289577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------+--------+----+-------+----------+----------+\n",
      "|               date|precipitation|temp_max|temp_min|wind|weather|temp_max_F|temp_min_F|\n",
      "+-------------------+-------------+--------+--------+----+-------+----------+----------+\n",
      "|2012-01-01 00:00:00|          0.0|    12.8|     5.0| 4.7|drizzle|      55.0|      41.0|\n",
      "|2012-01-02 00:00:00|         10.9|    10.6|     2.8| 4.5|   rain|      51.1|      37.0|\n",
      "|2012-01-03 00:00:00|          0.8|    11.7|     7.2| 2.3|   rain|      53.1|      45.0|\n",
      "|2012-01-04 00:00:00|         20.3|    12.2|     5.6| 4.7|   rain|      54.0|      42.1|\n",
      "|2012-01-05 00:00:00|          1.3|     8.9|     2.8| 6.1|   rain|      48.0|      37.0|\n",
      "+-------------------+-------------+--------+--------+----+-------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# degF = (degC * 1.8) + 32\n",
    "from pyspark.sql.functions import month, year, quarter, expr, sum as add, mean\n",
    "# convert temp to fahrenheit\n",
    "weather.withColumn(\"temp_max_F\", expr(\"ROUND((temp_max*1.8)+32, 1)\"))\\\n",
    "       .withColumn(\"temp_min_F\", expr(\"ROUND((temp_min*1.8)+32, 1)\"))\\\n",
    "       .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3cdcd3",
   "metadata": {},
   "source": [
    "- Which month has the most rain, on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cfb0b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---------------------------+\n",
      "|month|year|total_monthly_precipitation|\n",
      "+-----+----+---------------------------+\n",
      "|    6|2012|                       75.1|\n",
      "|    2|2012|                       92.3|\n",
      "|    5|2012|         52.199999999999996|\n",
      "|    1|2012|         173.29999999999998|\n",
      "|    3|2012|                      183.0|\n",
      "|    4|2012|          68.09999999999998|\n",
      "|    8|2012|                        0.0|\n",
      "|   12|2012|                      174.0|\n",
      "|   10|2012|         170.29999999999998|\n",
      "|    9|2012|         0.8999999999999999|\n",
      "|   11|2012|                      210.5|\n",
      "|    7|2012|                       26.3|\n",
      "|    6|2013|                       33.1|\n",
      "|    1|2013|         105.69999999999997|\n",
      "|    5|2013|          60.49999999999999|\n",
      "|    2|2013|         40.300000000000004|\n",
      "|    3|2013|                       69.7|\n",
      "|    4|2013|         149.60000000000002|\n",
      "|   12|2013|          42.39999999999999|\n",
      "|    8|2013|                       34.4|\n",
      "+-----+----+---------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.withColumn(\"month\", month(\"date\"))\\\n",
    "       .withColumn(\"year\", year(\"date\"))\\\n",
    "       .groupBy(\"month\", \"year\").agg(add(\"precipitation\")\\\n",
    "                                     .alias(\"total_monthly_precipitation\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98b79450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(month=11, avg_monthly_rain=160.625)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rainiest_month = (\n",
    "    weather.withColumn(\"month\", month(\"date\"))\n",
    "    .withColumn(\"year\", year(\"date\"))\n",
    "    .groupBy(\"month\", \"year\")\n",
    "    .agg(add(\"precipitation\").alias(\"total_monthly_precipitation\"))\n",
    "    .groupBy(\"month\")\n",
    "    .agg(mean(\"total_monthly_precipitation\").alias(\"avg_monthly_rain\"))\n",
    "    .sort(col(\"avg_monthly_rain\").desc())\n",
    "    .first()\n",
    ")\n",
    "rainiest_month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd6d8bc",
   "metadata": {},
   "source": [
    "November was the rainiest month, with an average precipitation of 160.625."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904c40a0",
   "metadata": {},
   "source": [
    "- Which year was the windiest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c03ae5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(year=2012, total_yearly_wind=1244.7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windiest_month = (\n",
    "    weather.withColumn(\"year\", year(\"date\")) # add year column\n",
    "    .groupBy(\"year\") # make each year a row\n",
    "    .agg(add(\"wind\").alias(\"total_yearly_wind\")) # aggregate by total wind per year\n",
    "    .sort(col(\"total_yearly_wind\").desc()) # sort wind totals\n",
    "    .first() # get windiest year\n",
    ")\n",
    "windiest_month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6dede6",
   "metadata": {},
   "source": [
    "2012 was the windiest year, with a wind total of 1244.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b854fdd7",
   "metadata": {},
   "source": [
    "- What is the most frequent type of weather in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8944a01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|weather|count|\n",
      "+-------+-----+\n",
      "|    fog|   38|\n",
      "+-------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.withColumn(\"month\", month(\"date\"))\\ # create month column\n",
    ".filter(col(\"month\") == 1)\\ # show only january records\n",
    ".groupby(\"weather\")\\ # make each weather type a row \n",
    ".count()\\ # aggregate by count\n",
    ".sort(col(\"count\").desc())\\ # sort descending by count\n",
    ".show(1) # show first record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42d1449",
   "metadata": {},
   "source": [
    "- What is the average high and low temperature on sunny days in July in 2013 and 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656d43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.withColumn(\"month\", month(\"date\"))\\\n",
    ".withColumn(\"year\", year(\"date\"))\\\n",
    ".groupby(\"month\", \"year\")\\\n",
    ".agg(mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b6cb79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "| average_high_temp| average_low_temp|\n",
      "+------------------+-----------------+\n",
      "|26.828846153846158|14.18269230769231|\n",
      "+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.filter(month(\"date\") == 7)\\\n",
    ".filter(year(\"date\") > 2012)\\\n",
    ".filter(year(\"date\") < 2015)\\\n",
    ".filter(col(\"weather\") == lit(\"sun\"))\\\n",
    ".agg(\\\n",
    "    avg(\"temp_max\").alias(\"average_high_temp\"),\n",
    "    avg(\"temp_min\").alias(\"average_low_temp\"),\n",
    ")\\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e126eb",
   "metadata": {},
   "source": [
    "- What percentage of days were rainy in q3 of 2015?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "660e1ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           avg(rain)|\n",
      "+--------------------+\n",
      "|0.021739130434782608|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.filter(year(\"date\") == 2015)\\\n",
    ".filter(quarter(\"date\") == 3)\\\n",
    ".select(when(col(\"weather\") == \"rain\", 1).otherwise(0).alias(\"rain\"))\\\n",
    ".agg(mean(\"rain\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066e77a9",
   "metadata": {},
   "source": [
    "- For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb69541a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "|year|          avg(rain)|\n",
      "+----+-------------------+\n",
      "|2012|0.48360655737704916|\n",
      "|2013|0.41643835616438357|\n",
      "|2014|  0.410958904109589|\n",
      "|2015|0.39452054794520547|\n",
      "+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.withColumn(\"year\", year(\"date\"))\\ # add year column\n",
    ".select(when(col(\"precipitation\") > 0, 1).otherwise(0).alias(\"rain\"), \"year\")\\ # convert to binary based on whether or not it rained\n",
    ".groupby(\"year\")\\ # one value per year\n",
    ".agg(mean(\"rain\")).show() # show pct of rainy days per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d22b39f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
