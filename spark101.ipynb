{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5087600",
   "metadata": {},
   "source": [
    "### 1. Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "- The name of the column should be `language`\n",
    "- View the schema of the dataframe\n",
    "- Output the shape of the dataframe\n",
    "- Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77df29af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "\n",
    "# create spark environment\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9a3b63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scala</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language\n",
       "0   python\n",
       "1      sql\n",
       "2     html\n",
       "3     ruby\n",
       "4        c\n",
       "5    scala"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create pandas dataframe\n",
    "p_df = pd.DataFrame({'language':['python', 'sql', 'html', 'ruby', 'c', 'scala']})\n",
    "p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b8f798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark dataframe\n",
    "df = spark.createDataFrame(p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aafd271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d92c53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape:  6  x  1\n"
     ]
    }
   ],
   "source": [
    "# output shape\n",
    "print(\"DataFrame shape: \", df.count(), \" x \", len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65d21e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "|  python|\n",
      "|     sql|\n",
      "|    html|\n",
      "|    ruby|\n",
      "|       c|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view first 5 records\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac97952c",
   "metadata": {},
   "source": [
    "### 2. Load the `mpg` dataset as a spark dataframe.\n",
    "\n",
    "#### a. Create 1 column of output that contains a message like the one below for each record:\n",
    "\n",
    "    The 1999 audi a4 has a 4 cylinder engine.\n",
    "\n",
    "> Hint: You will need to concatenate values that already exist in the data with string literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6436d4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from pydataset import data\n",
    "\n",
    "# create dataframe\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))\n",
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bae56559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------+\n",
      "|concat(The , year,  , manufacturer,  , model,  has a , cyl,  cylinder engine.)|\n",
      "+------------------------------------------------------------------------------+\n",
      "|The 1999 audi a4 has a 4 cylinder engine.                                     |\n",
      "|The 1999 audi a4 has a 4 cylinder engine.                                     |\n",
      "|The 2008 audi a4 has a 4 cylinder engine.                                     |\n",
      "|The 2008 audi a4 has a 4 cylinder engine.                                     |\n",
      "|The 1999 audi a4 has a 6 cylinder engine.                                     |\n",
      "+------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import concat\n",
    "\n",
    "# create string column\n",
    "mpg.select(concat(lit(\"The \"),\n",
    "                  mpg.year,\n",
    "                  lit(\" \"),\n",
    "                  mpg.manufacturer,\n",
    "                  lit(\" \"),\n",
    "                  mpg.model,\n",
    "                  lit(\" has a \"),\n",
    "                  mpg.cyl,\n",
    "                  lit(\" cylinder engine.\"))).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f30913f",
   "metadata": {},
   "source": [
    "#### b. Transform the trans column so that it only contains either manual or auto.\n",
    "\n",
    "> Hint: Consider spark string methods and `when().otherwise()` chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf732b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|     model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+----------+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|        a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|        a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|        a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|        a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|        a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "|        audi|        a4|  2.8|1999|  6|manual(m5)|  f| 18| 26|  p|compact|\n",
      "|        audi|        a4|  3.1|2008|  6|  auto(av)|  f| 18| 27|  p|compact|\n",
      "|        audi|a4 quattro|  1.8|1999|  4|manual(m5)|  4| 18| 26|  p|compact|\n",
      "|        audi|a4 quattro|  1.8|1999|  4|  auto(l5)|  4| 16| 25|  p|compact|\n",
      "|        audi|a4 quattro|  2.0|2008|  4|manual(m6)|  4| 20| 28|  p|compact|\n",
      "+------------+----------+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# preview dataframe\n",
    "mpg.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93efea85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|     trans|trans_type|\n",
      "+----------+----------+\n",
      "|  auto(l5)|      auto|\n",
      "|manual(m5)|    manual|\n",
      "|manual(m6)|    manual|\n",
      "|  auto(av)|      auto|\n",
      "|  auto(l5)|      auto|\n",
      "|manual(m5)|    manual|\n",
      "|  auto(av)|      auto|\n",
      "|manual(m5)|    manual|\n",
      "|  auto(l5)|      auto|\n",
      "|manual(m6)|    manual|\n",
      "|  auto(s6)|      auto|\n",
      "|  auto(l5)|      auto|\n",
      "|manual(m5)|    manual|\n",
      "|  auto(s6)|      auto|\n",
      "|manual(m6)|    manual|\n",
      "|  auto(l5)|      auto|\n",
      "|  auto(s6)|      auto|\n",
      "|  auto(s6)|      auto|\n",
      "|  auto(l4)|      auto|\n",
      "|  auto(l4)|      auto|\n",
      "+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from pyspark.sql.functions import when, regexp_extract, regexp_replace\n",
    "\n",
    "mpg.select(mpg.trans, \n",
    "           when(mpg.trans.like(\"a%\"), \"auto\")\n",
    "           .otherwise(\"manual\")\n",
    "           .alias(\"trans_type\")\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac019c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
